version: "3.8"

services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cards-against-humanity-api
    ports:
      - "${API_PORT:-3300}:3300"
    env_file:
      - .env
    environment:
      - NODE_ENV=production
      - PORT=3300
      - HOST=0.0.0.0
      - DATABASE_URL=${DATABASE_URL}
      - SESSION_SECRET=${SESSION_SECRET:-cah-super-secret-session-key-2025}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      # Ollama (local LLM fallback)
      - OLLAMA_BASE_URL=http://ollama:11434/v1
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2.5:3b}
    restart: unless-stopped
    depends_on:
      - db
      - ollama
    networks:
      - app-network

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
      args:
        # Empty = same-origin (nginx proxies /api to backend)
        - VITE_API_URL=${VITE_API_URL:-}
    container_name: cards-against-humanity-client
    ports:
      - "${CLIENT_PORT:-6609}:80"
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - app-network

  db:
    image: postgres:15-alpine
    container_name: cards-against-humanity-db
    ports:
      - "${DB_PORT:-5457}:5432"
    env_file:
      - .env
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password}
      - POSTGRES_DB=cards_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - app-network

  ollama:
    image: ollama/ollama:latest
    container_name: cards-against-humanity-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - app-network

volumes:
  postgres_data:
  ollama_data:

networks:
  app-network:
    driver: bridge

